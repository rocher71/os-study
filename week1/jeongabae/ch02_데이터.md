# 02-1 0과 1로 숫자를 표현하는 방법

- 0과 1을 나타내는 가장 작은 정보 단위 : bit
- 바이트 : 8개의 비트
- 1킬로바이트 :  1000바이트
- 1메가바이트 : 1000킬로바이트
- 1기가바이트 : 1000매가바이트
- 1테라바이트 : 1000기가바이트

** 워드 : CPU가 한 번에 처리할 수 있는 데이터 크기

인텔의 x86 cpu는 32비트 워드 CPU

x64CPU는 64 CPU는 64비트 워드 CPU

## 이진수

- 이진수
- 십진수

- 이진수의 음수 표현
    - 가장 널리 사용되는 방법 : **2의 보수**
    - 사전적 의미 : 어떤 수를 그보다 큰 2^n에서 뺀 값을 의미 → 하지만 이렇게 이해할 필요 없음.
    - 쉽게 이해하려면 모든 0과 1을 뒤집고 거기에 더한 값으로 이해하면 됨!
    - ex) 11의 2의 보수는 01
    - 2의 보수 표현의 한계
        - 0이나 2^n형태의 이진수에 2의 보수를 취하면 원하는 음수값 얻을 수 없음.
            - 0은 자리 올림이 발생한 비트의 1을 버림
            - 2^n보수를 취하는 경우 자기 자신이 되어 버리는 문제
            - 즉, n비트로는 -2^n과 2^n이라는 수를 동시에 표현할 수 없음.

**이진수만 봐서 음수인지 양수인지 구분하기 어렵

→ 그래서 컴퓨터 내부에서 어떤 수 다룰 때는 양수 음수 구분하기 위해 flag(플래그) 사용

## 16진수

숫자 뒤에 아래첨자 (16)을 붙이거나 숫자 앞에 0x를 붙여 구분함.
<img width="603" alt="image" src="https://github.com/user-attachments/assets/5634015d-5bf0-4589-b886-a08762fa1065" />


- 16진수를 사용하는 주된 이유?
    - 2진수 → 16진수, 16→2진수로 변환 쉬워서
    - 16→2진수로 변환법 : 한 글자를 4비트의 이진수로 간주
        
       <img width="570" alt="image" src="https://github.com/user-attachments/assets/75d8fbdf-d491-4d11-80d3-e43fb9c66a77" />

        

---

# 02-2 0과 1로 문자를 표현하는 방법

## 문자 집합과 인코딩

- 문자 집합 : 컴퓨터가 인식하고 표현할 수 있는 문자의 모음
- 문자 인코딩 : 0과 1로 변호나해서 컴퓨터가 이해할 수 있게 하는거
↔ 문자 디코딩 : 사람이 이해할 수 있게 바꾸는거.

## 아스키 코드

- 총 128 문자 표현 ㄱㄴ
- 아스키 문자에 대응된 고유의 수 : 아스키 코드
- 아스키 코드는 이진수(아스키 문자가 아스키 코드로 **인코딩** 된 것)
    - ex) ‘A’는 65, ‘a’는 97
- 단점 : 한글 표현 불가….등

cf) 확장 아스키 : 아스키 코드에 1비트를 추가 (표현 가능한 문자 수 256)

## EUC-KR

- 한글 인코딩 방식
- cf) 한글 인코딩종류
    - 완성형 인코딩 방식 : 초,중,종성 조합으로 이루어진 완성된 하나의 글자에 고유한 코드 부여 → **EUC-KR도 이거 사용**
    - 조합형 인코딩 방식 : 초,중, 종성을 위한 비트열 할당하여 그것의 조합으로 글자 코드 완성
- 초,중,종성이 모두 결합된 한글 단어에 2바이트 크기 코드 부여
- 모든 한글을 표현할 수는 X (→ 그래서 등장한게 CP949 (feat.마이크로소프트))

## 유니코드와 UTF-8

- 유니코드 : EUC-KR보다 훨씬 다양한 한글 포함, 대부분의 나라의 문자, 특수문자, 화살표나 이모티콘까지도 코드로 표현할 수 있는 통일된 문자 집합
- UTF-8 : 유니코드 인코딩 방법(유니코드 문자에 부여된 값을 인코딩하는 방식)
